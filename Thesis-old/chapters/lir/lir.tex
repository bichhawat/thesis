\chapter{Bounding Information Leaks Dynamically}
\label{ch:lir}

Information flow control allows tracking of sensitive and private
information while preventing leaks to unauthorized public 
channels. However, in some cases it is required that (some part of) 
the sensitive data be accessible over certain public channels. This
violates the security property of non-interference but is needed for  
practical reasons. This is generally achieved by specifying special
declassification policies, which allow for such release of
information. For instance, the declassification policy 
\lstinline{declassify(pwd == input)} would treat the result of the
equality check (\lstinline{pwd == input})  as public, thus allowing
information to be released to the user. The enforcement generally
requires \TT{declassify} annotations to be added to the code to
specify which operations need to release the value. Most of the
approaches require policy specifications by the developer that define
\emph{what} information can be released by the program when the data
to be declassified is part of the untrusted code; else the untrusted
code can arbitrarily add \TT{declassify} annotations and release
information at will. 

% This ensures that
% the untrusted code does not get access to the data not intended for
% it, i.e., in the example above, the code can specify
% \lstinline{declassify(pwd)} and leak the complete password if there is
% no specification of what (part of) data in \TT{pwd} can be
% declassified.  

% An alternative approach to declassification is to quantify the amount
% of information about a sensitive value that can be released by
% a program and to determine an acceptable upper bound, which accepts 
% or rejects the program. The information released is generally
% quantified by computing the difference in the entropy, a measure of
% uncertainty, of information contained in the sensitive value before
% and after the release with respect to an adversary. Most analysis
% methods that have been proposed until now are static in nature and
% quite a few of these determine an average worst-case bound on the
% amount of information that a program can release as a whole. However,
% all of these measures rely on the fact that the probability
% distribution of the output values is known upfront. 

% The motivation of this work is to provide an analysis that bounds
% information leaks dynamically at runtime and to prove that the
% approach is sound. Previously proposed quantitative information flow
% analysis methods in general yield leakage bounds over all possible
% executions of a program. A dynamic analysis, on the other hand,
% considers only the path being taken in the current execution, which in 
% general consensus seems to be unsound for quantifying information
% leaks. However, such an analysis would prove useful in scenarios like
% the Web where the program to be analyzed might only be available at
% runtime and one needs to only bound the amount of information released
% by the program about a sensitive value to untrusted
% sources~\cite{bielovaPLAS}. Additionally, it seems intuitive to reason about the path
% taken by the current execution of the program alone. Such leaks can be
% accounted for and bounded in the dynamic analysis presented in this
% chapter. 

An alternative approach to declassification is to \emph{quantify} the
amount of information a program releases about a sensitive value and
to determine an acceptable upper bound, which accepts or rejects the
program. The information released is generally quantified by computing
the difference in the entropy, a measure of uncertainty, of
information contained in the sensitive value before and after the
release with respect to an adversary~\referp{shannon, guessing,
  smith2009, clarkson2009, csf12GLeakage}. Research in quantitative
information flow has focussed on statically analyzing the program
and determining a worst-case bound on the amount of information that a
program can release as a whole~\referp{denning82, clark, clarkson2009,
  smith2009, backes, kopf}. These approaches rely on the assumption
that the probability distribution of the output values is known 
upfront. 

Quantitative information flow analysis methods, in general, yield
leakage bounds over all possible executions of a program. A dynamic
analysis, on the other hand, considers only the path being taken in
the current execution, which in general consensus seems to be unsound
for quantifying information leaks. However, such an analysis would prove
useful in scenarios like the Web where the program to be analyzed
might only be available at runtime and one needs to only bound the
amount of information released by the program about a sensitive value
to untrusted sources~\referp{bielovaPLAS}. 

% McCamant and Ernst~\cite{mccamant} provide a dynamic
% analysis for quantifying information flows but do not prove the
% soundness of their approach. They, however, provide a simulation-based 
% proof for quantifying the amount of information released by the
% program about a secret for a simple system with a two-level
% lattice. However, it is unclear how their technique scales for
% multiple security levels or multiple secrets in the system. Moreover, 
% the approach is more suitable for quantification than bounding
% information leaks; bounding information leaks introduces additional
% issues as detailed in later sections. Other prior work~\cite{csf13} used
% self-information to quantify the number of bits of information that
% could be leaked about a secret value. However, this technique requires
% the knowledge of the probability distribution or individual probabilities
% of the outputs that are based on secret values. In cases where it is
% difficult to determine the probability of the outputs upfront, the use
% of this measure for analysis does not help much. 

In the context of dynamic analysis, bounding information leaks helps
control the information leakage at runtime. The motivation of this
work is, thus, to provide an analysis that bounds information leaks
dynamically at runtime and to prove that the approach is sound. 
McCamant and Ernst~\refert{mccamant} provide the only dynamic 
quantitative information flow analysis but do not prove the
soundness of their approach. They, however, provide a simulation-based 
proof~\referp{plas07} for quantifying the amount of information
released by the program about a secret for a simple system with a
two-level lattice. They track information flow more finely at the
granularity of bits by restricting the language's variables to single
bits. They maintain a shadow bit for every variable that
indicates the secrecy level (public or secret) of the value in the
variable. However, it is unclear how their technique scales for
multiple security levels or multiple secrets in the system. 

Moreover, the approach by McCamant and Ernst~\refert{mccamant} 
is more suitable for quantification rather than for \emph{bounding} 
information leaks; bounding information leaks introduces additional 
non-trivial complications and leakage channels as detailed in later
sections. Other prior work by Besson \emph{et al.}~\referp{csf13} 
used self-information to
quantify the number of bits of information that could be leaked about
a secret value. However, this technique requires the knowledge of the
probability distribution or individual probabilities of the outputs
that are based on secret values. In cases where it is difficult to
determine the probability of the outputs upfront, the use of this
measure for analysis does not help much.   

% We build our proof strategy on similar lines. 
% The idea is that for every output that the program produces,
% which depends on a secret value, one can assign a unique code, which
% is generally represented as a bit-stream. Given that we have 
% uniquely decodable codes for different outputs, the average length of
% the code (average number of bits per output) is always greater than
% or equal to the Shannon entropy of the program outputs~\cite{shannon},
% which gives us a clear upper bound on the number of bits of
% information released through different runs of the program.

% Our analysis is flow-sensitive, which concentrates our interest to
% information leaks due to implicit flows. In our approach, every secret
% value has a release budget associated with it, which specifies the
% number of bits about the value that can be released and to what level
% the release can happen. As part of the declassification semantics, we
% generate a trace of all the released values when information release
% occurs at the comparison operations. The trace in this case  
% corresponds to the decodable code. To prove that our approach is
% sound, we show that every trace generated by the program on different
% executions corresponds to a unique set of information about high
% values. Thus, every different trace the program generates is a
% uniquely-decodable code, the average of which would be greater than
% the Shannon entropy of the secrets in the program. We show the
% uniqueness of the code by simulating the program execution for every  
% attacker-level with the attacker's view of the memory and the
% generated trace. The secret parts of the memory are unknown to the
% attacker and marked accordingly. At declassification points, we remove
% the first value from the trace and use it instead of the ``unknown''
% secret value. We then prove that the attacker's view of the final memory
% obtained by running the simulation is observationally equivalent to
% the attacker's view of the final memory obtained by executing the
% program in the declassification semantics. The additional challenge
% lies in the fact that we have multiple levels in the lattice and the
% declassification can happen to any of these levels, which needs to be
% accounted for properly in the generated trace as well. We also show
% that as the information released about a secret value at any program
% point is a 1-bit value, we account for it by deducting one from the
% budget of that secret value at that point, if it is allowed. 

% An orthogonal motivation for this approach is that quite a few flows
% do not leak a lot of information. In practice most implicit flows leak
% a single bit of information only, which might be required for
% providing proper functionality. King \emph{et
%   al.}~\cite{king08implicit} investigate the occurrence of implicit
% flows in some standard algorithms and discuss both the pros and cons
% of handling implicit flows. Russo \emph{et al.}~\cite{implicit} also
% observe that implicit flows cannot be exploited in non-malicious code
% to leak secrets efficiently. Unfortunately, allowing information release
% when only an insignificant amount of information is leaked can be
% widened to leak the complete secret~\cite{relSec,delRelease}. 

This chapter explores an alternative approach, where the developer can
specify a \emph{budget} for every sensitive value in the system
(defaulting to zero if not specified), which is basically an upper
bound on the amount of information allowed to leak about that
value. An underlying enforcement mechanism ensures that no more
information about that value is leaked than what is specified by the
budget.  

\begin{lstlisting}[float,belowskip=-0.5em,caption=Age-based Advertisement, label=egLeak]
 age $=$ getCurrentAge(birthday, birthyear);
 if (age $<$ 18)
    preference $=$ "child";
 else
    preference $=$ "adult";
\end{lstlisting}

Additionally, in scenarios
like the Web where the untrusted third-party code changes quite often,
it is difficult for the developer to keep up with the changes and
modify the \emph{what} policy specifications accordingly. For
instance, consider the program snippet in Listing~\ref{egLeak} where
the displayed advertisements for some webpage depend on the viewer's
age. The exact age is considered sensitive data, but in order to
provide its functionality only  an abstraction of the age is required,
namely whether \lstinline{age < 18}. The developer might specify
\lstinline{declassify(age < 18)} as a declassification policy.
However, different jurisdictions might entail adaptations to this rule  
(requiring a different check on \lstinline{age}), resulting in a
cumbersome process where the developer needs to update the policy
frequently. If, however, the developer associates a budget of $3$ with
the initial value in the variable \lstinline{age} (meaning that only
$3$ bits of information about \lstinline{age} are allowed to leak),
this example will be accepted in the envisioned model. If the
advertiser changes the criteria to include another check whether the
user is a teenager, this comparison can be included without requiring 
any change to the policy. The soundness of the underlying enforcement 
would ensure that no more information than the specified budget can
ever leak.  

Bounding information leaks has additional advantages --- it provides 
a formal meaning for allowing certain operations like the one 
described in Listing~\ref{egLeak} while establishing important
security properties related to them. There are a number of 
real-world programs that allow a limited number of such 
operations to be performed, e.g., a password checker allows $3$ tries
before it locks the user's account. 

Bounding information leaks in a purely dynamic setting is still largely 
an open problem. As the property of non-interference does not allow 
any information release, this chapter proposes a new security 
property, \emph{limited information release}, an end-to-end guarantee 
that allows the flow of secret information to public channels in a 
controlled manner by declassifying fragments of the secret. The 
policy enforces that the only information leaked about the secrets 
by a program is bounded by their pre-specified budgets. 
A sound enforcement of the property is descirbed and proven sound 
information-theoretically by coding the outputs generated through
information releases and showing that the output codes are
uniquely-decodable. We utilize an important result by
Shannon~\refert{shannon}, which states  that the average length of
uniquely-decodable codes upper bounds the Shannon entropy of the
outputs. 

% The challenge, however, is to build an enforcement mechanism that
% quantifies such information leaks soundly at runtime. As  a solution,
% this chapter proposes \emph{limited information release}, an
% information release policy that allows the flow of secret information
% to public channels in a controlled manner by declassifying fragments
% of the secret. The 
% policy enforces that the information leaked about the secrets by a
% program is bounded by the specified budgets. The soundness of
% the approach is proven by coding the outputs generated through
% information leaks and by showing that the codes are
% uniquely-decodable. The proof utilizes an important result
% by~\cite{shannon} that the average length of uniquely-decodable codes
% upper bounds the Shannon entropy of the outputs. 

% \medskip

\input{chapters/lir/overview}
\input{chapters/lir/lir-policy}
\input{chapters/lir/language}
\input{chapters/lir/dynamicqif}
\input{chapters/lir/decoding}